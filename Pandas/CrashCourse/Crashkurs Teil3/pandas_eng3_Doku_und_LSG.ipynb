{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "<center><h1> Pandas for Data Science</h1></center>\n",
    "<center><h2> Data processing </h2></center>\n",
    "<hr style=\"border-width:2px;border-color:#75DFC1\">\n",
    "\n",
    "\n",
    "> Data processing can be described in 4 essential operations: **filtering**, **merging**, **ordering** and **grouping**.\n",
    ">\n",
    "> The DataFrame class has risen to prominence in the field of data manipulation precisely because it often only requires repetition or combination of these four operations.\n",
    ">\n",
    "> In this lesson, you will learn how to use these 4 operations of data processing.\n",
    ">\n",
    "\n",
    "\n",
    "* Before starting this notebook, **run the following cell** in order to retrieve the work done in the previous exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports ###\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Data import\n",
    "transactions = pd.read_csv(\"C:/Users/OlhaIshchenko/Documents/Daten_Analyse/unterricht/csv_Datei/transactions.csv\", \n",
    "                           sep =',', index_col = \"transaction_id\")\n",
    "\n",
    "# Removal of duplicates\n",
    "transactions = transactions.drop_duplicates(keep = 'first')\n",
    "\n",
    "# Changing the names of the columns\n",
    "new_names =  {'Store_type' : 'store_type',\n",
    "              'Qty'        : 'qty',\n",
    "              'Rate'       : 'rate',\n",
    "              'Tax'        : 'tax'}\n",
    "\n",
    "transactions = transactions.rename(new_names, axis = 1)\n",
    "\n",
    "### Handling NAs ###\n",
    "\n",
    "#  We replace the NAs in 'prod_subcat_code' by -1\n",
    "transactions['prod_subcat_code'] = transactions['prod_subcat_code'].fillna(-1).astype(int)\n",
    "\n",
    "# We compute the mode of 'store_type'\n",
    "store_type_mode = transactions['store_type'].mode()\n",
    "\n",
    "# We replace the NAs of 'store_type' by its mode\n",
    "transactions['store_type'] = transactions['store_type'].fillna(transactions['store_type'].mode()[0])\n",
    "\n",
    "# Removal of rows where 'rate', 'tax' and 'total_amt' are all NAs\n",
    "transactions = transactions.dropna(axis = 0, how = 'all', subset = ['rate', 'tax', 'total_amt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Filtering a `DataFrame` with binary operators.\n",
    "\n",
    "> Filtering involves **selecting** a subset of **rows** in a DataFrame based on a given **condition**. This process aligns with what we previously referred to as conditional indexing, though in database management, \"filtering\" is the preferred term.\n",
    ">\n",
    "> It's worth noting that we cannot employ the logical operators `and` and `or` for filtering with multiple conditions. These operators can introduce **ambiguities** that pandas cannot effectively manage for filtering.\n",
    ">\n",
    "> In this context, the appropriate operators for filtering based on multiple conditions are the binary **operators**:\n",
    ">\n",
    ">> - The 'and' operator: `&`.\n",
    ">>\n",
    ">> - The 'or' operator: `|`.\n",
    ">>\n",
    ">> - The 'not' operator: `-`.\n",
    "\n",
    "> While these operators share similarities with logical operators, their evaluation methods are not identical.\n",
    "\n",
    "### The 'and' operator: `&`.\n",
    "\n",
    "> The `&` operator is employed to filter a `DataFrame` based on multiple conditions that need to be satisfied **simultaneously**.\n",
    ">\n",
    "> <span style=\"color:#09b038; text-decoration : underline\"> Example: </span>\n",
    ">\n",
    "> Let's consider the `DataFrame` `df` that provides information about apartments in Paris:\n",
    ">\n",
    "> |       | district         | year | surface |\n",
    "> |-------|------------------|------|---------|\n",
    "> | **0** | 'Champs-Elysées' | 1979 | 70      |\n",
    "> | **1** | 'Europe'         | 1850 | 110     |\n",
    "> | **2** | 'Père-Lachaise'  | 1935 | 55      |\n",
    "> | **3** | 'Bercy'          | 1991 | 30      |\n",
    ">\n",
    "> If our objective is to locate an apartment from the year 1979 **and** with a surface area exceeding 60 square meters, we can filter the rows in `df` using the following code:\n",
    ">\n",
    "> ``` py\n",
    ">\n",
    "> # Filtering of the DataFrame on the 2 previous conditions\n",
    "> print(df[(df['year'] == 1979) & (df['surface']> 60)])\n",
    "> ```\n",
    ">\n",
    "> ```\n",
    "> >>>         district  year  surface\n",
    "> >>> 0  Champs-Elysées  1979       70\n",
    "> ```\n",
    ">\n",
    "> The conditions must be written **between parentheses** to eliminate any ambiguity on the **order of evaluation** of the conditions. Indeed, if the conditions are not properly separated, we will get the following error:\n",
    ">\n",
    "> ``` python\n",
    "> print(df[df['year'] == 1979 & df['surface']> 60])\n",
    "> ```\n",
    "> ```\n",
    "> >>> ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
    "> ```\n",
    "\n",
    "### The 'or' operator: `|`.\n",
    "\n",
    "> The operator `|` is used to filter a `DataFrame` on several conditions of which **one at least** must be verified.\n",
    ">\n",
    "> <span style=\"color:#09b038; text-decoration : underline\"> Example: </span>\n",
    ">\n",
    "> Consider the same `DataFrame` `df`:\n",
    ">\n",
    "> |       | district         | year | surface |\n",
    "> |-------|------------------|------|---------|\n",
    "> | **0** | 'Champs-Elysées' | 1979 | 70      |\n",
    "> | **1** | 'Europe'         | 1850 | 110     |\n",
    "> | **2** | 'Père-Lachaise'  | 1935 | 55      |\n",
    "> | **3** | 'Bercy'          | 1991 | 30      |\n",
    ">\n",
    "> If we want to find an apartment that dates after 1900 **or** is located in the Père-Lachaise district, we can filter the lines of `df` with the following code:\n",
    ">\n",
    "> ``` py\n",
    ">\n",
    "> # Filtering of the DataFrame on the 2 previous conditions\n",
    "> print(df[(df['year']> 1900) | (df['district'] == 'Père-Lachaise')])\n",
    "> ```\n",
    "> ```\n",
    "> >>>          district  year  surface\n",
    "> >>> 0  Champs-Elysées  1979       70\n",
    "> >>> 2  Père-Lachaise   1935       55\n",
    "> >>> 3  Bercy           1991       30\n",
    "> ```\n",
    ">\n",
    ">\n",
    "### The 'not' operator: `-`.\n",
    ">\n",
    ">The `-` operator allows us to filter a `DataFrame` based on a conditions, of which **the negative** must be satisfied.\n",
    ">\n",
    "><span style=\"color:#09b038; text-decoration : underline\"> Example: </span>\n",
    ">\n",
    ">Let's consider the same `DataFrame` `df`:\n",
    ">\n",
    ">|       | district         | year | surface |\n",
    ">|-------|------------------|------|---------|\n",
    ">| **0** | 'Champs-Elysées' | 1979 | 70      |\n",
    ">| **1** | 'Europe'         | 1850 | 110     |\n",
    ">| **2** | 'Père-Lachaise'  | 1935 | 55      |\n",
    ">| **3** | 'Bercy'          | 1991 | 30      |\n",
    ">\n",
    ">If we want to find an apartment not located in Bercy district, we can filter `df` using the following code:\n",
    ">\n",
    "> ``` py\n",
    "> # Filtering of the DataFrame on the the negation of a condition\n",
    "> print(df[-(df['district'] == 'Bercy')])\n",
    "> ```\n",
    "> ```\n",
    "> >>> district year surface\n",
    "> >>> 0 Champs-Elysées 1979 70\n",
    "> >>> 1 Europe 1850 110\n",
    "> >>> 2 Père-Lachaise 1935 55\n",
    "> ```\n",
    ">\n",
    ">\n",
    ">\n",
    "\n",
    "\n",
    "* **(a)** Display the first 5 lines of the `transactions` `DataFrame`.\n",
    "\n",
    "* **(b)** Create a new `DataFrame` named **`e_shop`** from **`transactions`**. Include only transactions that were carried out in stores of type **`'e-Shop'`** with a total amount greater than 5000. This selection involves the `'store_type'` and `'total_amt'` columns.\n",
    "\n",
    "* **(c)** Similarly, create a `DataFrame` named **``teleshop``** which contains the transactions made in stores of type **`'TeleShop'`** with a total amount of more than 5000.\n",
    "\n",
    "* **(d)** Determine which type of store, either `'e-Shop'` or `'TeleShop'`, has the highest number of transactions with amounts exceeding € 5,000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transactions over 5000€ for e-shop : 1185\n",
      "Number of transactions over 5000€ for teleshop : 532\n"
     ]
    }
   ],
   "source": [
    "# Creation of e_shop et teleshop\n",
    "e_shop = transactions[(transactions['store_type'] == 'e-Shop') & (transactions['total_amt'] > 5000)]\n",
    "\n",
    "\n",
    "teleshop = transactions[(transactions['store_type'] == 'TeleShop') & (transactions['total_amt'] > 5000)]\n",
    "\n",
    "\n",
    "# We count the number of rows of each DataFrame. Other solutions are possible.\n",
    "print('Number of transactions over 5000€ for e-shop :', len(e_shop['total_amt']))\n",
    "print('Number of transactions over 5000€ for teleshop :', len(teleshop['total_amt']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **(e)** Load the data from the files `'customer.csv'` and `'prod_cat_info.csv'` into two separate DataFrames named **`customer`** and **`prod_cat_info`**.\n",
    "\n",
    "* **(f)** In the `customer` DataFrame, there are two missing values in both the `Gender` and `city_code` columns. Fill these missing values with the mode of their respective columns using the `fillna` method along with the `mode` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = pd.read_csv('C:/Users/OlhaIshchenko/Documents/Daten_Analyse/unterricht/csv_Datei/customer.csv')\n",
    "prod_cat_info = pd.read_csv('C:/Users/OlhaIshchenko/Documents/Daten_Analyse/unterricht/csv_Datei/prod_cat_info.csv')\n",
    "\n",
    "customer['Gender'] = customer['Gender'].fillna(customer['Gender'].mode()[0])\n",
    "customer['city_code'] = customer['city_code'].fillna(customer['city_code'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Joining `Dataframes`: `concat` function and `merge` method.\n",
    "\n",
    "### Concatenation of `DataFrames` with `concat`\n",
    "\n",
    "> The `concat` function from the `pandas` module enables the concatenation of multiple `DataFrames`, either by stacking them vertically or by aligning them side by side.\n",
    ">\n",
    ">\n",
    "> ```python\n",
    "> pandas.concat(objs, axis, ...)\n",
    "> ```\n",
    ">\n",
    "> - The `objs` parameter takes a list of `DataFrames` to concatenate.\n",
    "> - The `axis` parameter specifies whether the concatenation should be vertical (`axis = 0`) or horizontal (`axis = 1`).\n",
    ">\n",
    ">\n",
    "> <br/>\n",
    "> <img src= 'https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/pd_concat_en.png', style = \"height:400px\">\n",
    "> <br/>\n",
    ">\n",
    "> When the number of rows or columns of the `DataFrames` does not match, the` concat` function fills the empty cells with `NaN`, as shown in the illustration below.\n",
    ">\n",
    "> <br/>\n",
    "> <img src= 'https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/pd_concat_none_en.png', style = \"height:400px\">\n",
    "> <br/>\n",
    ">\n",
    "\n",
    "* **(a)** Divide the **columns** of the **`transactions`** `DataFrame` in half, placing the first half in a `DataFrame` named **`part_1`**, and the second half in a `DataFrame` named **`part_2`**.\n",
    "\n",
    "* **(b)** Reconstruct the **`transactions`** data in a `DataFrame` named **`union`** by horizontally concatenating **`part_1`** and **`part_2`**.\n",
    "\n",
    "* **(c)** What happens if we concatenate `part_1` and `part_2` with the argument **`axis = 0`** filled in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>tran_date</th>\n",
       "      <th>prod_subcat_code</th>\n",
       "      <th>prod_cat_code</th>\n",
       "      <th>qty</th>\n",
       "      <th>rate</th>\n",
       "      <th>tax</th>\n",
       "      <th>total_amt</th>\n",
       "      <th>store_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80712190438</th>\n",
       "      <td>270351</td>\n",
       "      <td>28-02-2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>-772.0</td>\n",
       "      <td>405.300</td>\n",
       "      <td>-4265.300</td>\n",
       "      <td>e-Shop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29258453508</th>\n",
       "      <td>270384</td>\n",
       "      <td>27-02-2014</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1497.0</td>\n",
       "      <td>785.925</td>\n",
       "      <td>-8270.925</td>\n",
       "      <td>e-Shop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51750724947</th>\n",
       "      <td>273420</td>\n",
       "      <td>24-02-2014</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-791.0</td>\n",
       "      <td>166.110</td>\n",
       "      <td>-1748.110</td>\n",
       "      <td>TeleShop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93274880719</th>\n",
       "      <td>271509</td>\n",
       "      <td>24-02-2014</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1363.0</td>\n",
       "      <td>429.345</td>\n",
       "      <td>-4518.345</td>\n",
       "      <td>e-Shop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51750724947</th>\n",
       "      <td>273420</td>\n",
       "      <td>23-02-2014</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-791.0</td>\n",
       "      <td>166.110</td>\n",
       "      <td>-1748.110</td>\n",
       "      <td>TeleShop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cust_id   tran_date  prod_subcat_code  prod_cat_code  qty  \\\n",
       "transaction_id                                                              \n",
       "80712190438      270351  28-02-2014                 1              1   -5   \n",
       "29258453508      270384  27-02-2014                 5              3   -5   \n",
       "51750724947      273420  24-02-2014                 6              5   -2   \n",
       "93274880719      271509  24-02-2014                11              6   -3   \n",
       "51750724947      273420  23-02-2014                 6              5   -2   \n",
       "\n",
       "                  rate      tax  total_amt store_type  \n",
       "transaction_id                                         \n",
       "80712190438     -772.0  405.300  -4265.300     e-Shop  \n",
       "29258453508    -1497.0  785.925  -8270.925     e-Shop  \n",
       "51750724947     -791.0  166.110  -1748.110   TeleShop  \n",
       "93274880719    -1363.0  429.345  -4518.345     e-Shop  \n",
       "51750724947     -791.0  166.110  -1748.110   TeleShop  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting of the transactions DataFrame\n",
    "part_1 = transactions[transactions.columns[:4]]\n",
    "part_2 = transactions[transactions.columns[4:]]\n",
    "\n",
    "# Reconstitution of the transactions DataFrame by concatenation\n",
    "union = pd.concat([part_1,part_2], axis = 1)\n",
    "\n",
    "# If we were to concatenate by filling in the argument \"axis = 0\", we would obtain a DataFrame where half of\n",
    "# the valuers are NAs\n",
    "#\n",
    "# This is due to the fact that the argument 'axis = 0' forces the pd.concat function to create new ROWS\n",
    "# in part_1 but it cannot fill them correctly since part_1 and part_2 have no columns in common.\n",
    "union.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Merging `DataFrames` with the `merge` method\n",
    "\n",
    ">Two `DataFrames` can be combined through a process called merging, provided they share a common column. This is accomplished using the `merge` method of the `DataFrame` class, which has the following syntax:\n",
    ">\n",
    ">>```python\n",
    ">>merge(right, on, how, ...)\n",
    ">>```\n",
    ">\n",
    ">- The **`right`** parameter represents the `DataFrame` to be merged with the one calling the method.\n",
    ">\n",
    ">- The **`on`** parameter specifies the names of the columns in both `DataFrames` that will serve as references for the merge. These columns must be shared between the two.\n",
    ">\n",
    ">- The **`how`** parameter lets you choose the type of join to perform when merging the `DataFrames`. The available values for this parameter are based on SQL-style joins.\n",
    "\n",
    "The `how` parameter can take one of four values: `'inner'`, `'outer'`, `'left'`, or `'right'`. These will be illustrated using two sample `DataFrames` named `Persons` and `Vehicles` below:\n",
    ">\n",
    ">\n",
    "> | Name | Car |\n",
    "> | ---------- | ------------ |\n",
    "> | Lila | Twingo |\n",
    "> | Tiago | Clio |\n",
    "> | Berenice | C4 Cactus |\n",
    "> | Joseph | Twingo |\n",
    "> | Kader | Swift |\n",
    "> | Romy | Scenic |\n",
    ">\n",
    "> | Car | Price |\n",
    "> | ----------- | ------- |\n",
    "> | Twingo | 11000 |\n",
    "> | Swift | 14500 |\n",
    "> | C4 Cactus | 23000 |\n",
    "> | Clio | 16000 |\n",
    "> | Prius | 30000 |\n",
    ">\n",
    ">\n",
    ">>- **`'inner'`**: The inner join returns the rows where the values in the common columns are **found in both `DataFrames`**. It's important to note that this type of join may result in the loss of many entries. However, the inner join does not generate **NAs**.\n",
    ">>\n",
    ">>\n",
    ">> The result of the inner join `Persons.merge(right = Vehicles, on = 'Car', how = 'inner')` is shown below:\n",
    ">>\n",
    ">> <br>\n",
    ">> <img src= 'https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/pd_join_inner_en.png' style=\"height:700px\">\n",
    ">> <br>\n",
    ">> <br>\n",
    ">>\n",
    ">> - **`'outer'`**: The outer join combines the two `DataFrames` **in their entirety**. No row will be deleted. This method can generate **a lot of NAs**.\n",
    ">>\n",
    ">> The result of the outer join `Persons.merge(right = Vehicles, on = 'Car', how = 'outer')` is shown below:\n",
    ">>\n",
    ">> <br>\n",
    ">> <img src= 'https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/pd_join_outer_en.png' style=\"height:700px\">\n",
    ">> <br>\n",
    ">> <br>\n",
    ">>\n",
    ">>- **`'left'`**: The left join returns **all the rows** of the `DataFrame` on the **left** (i.e. the one calling the method), and complements them with the rows of the second `DataFrame` that match according to the values of the common column. This is the **default value for the `how`** parameter.\n",
    ">>\n",
    ">> The result of the left join `Persons.merge(right = Vehicles, on = 'Car', how = 'left')` is shown below:\n",
    ">>\n",
    ">> <br>\n",
    ">> <img src= 'https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/pd_join_left_en.png' style=\"height:700px\">\n",
    ">> <br>\n",
    ">> <br>\n",
    ">>\n",
    ">> - **`'right'`**: The right join returns **all the rows** of the `DataFrame` on the **right**, and complete them with the rows of the left `DataFrame` which coincide according to the values of the common column.\n",
    ">>\n",
    ">> The result of the right join `Persons.merge(right = Vehicles, on = 'Car', how = 'right')` is shown below:\n",
    ">>\n",
    ">> <br>\n",
    ">> <img src= 'https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/pd_join_right_en.png' style=\"height:700px\">\n",
    ">> <br>\n",
    ">> <br>\n",
    ">\n",
    ">> Performing a left join, right join, or outer join followed by a `dropna(how = 'any')` is essentially equivalent to an inner join.\n",
    ">\n",
    "> The `customer` `DataFrame` holds customer information under the `'cust_id'` column, which corresponds to the customer ID in `transactions`.\n",
    ">\n",
    "> The `'customer_Id'` column in the `customer` `DataFrame` will be used as the linking column for joining `transactions` and `customer`. This will enhance the `transactions` `DataFrame` with supplementary information.\n",
    ">\n",
    "> *(d)* Rename the **`'customer_Id'`** column in the **`customer`** `DataFrame` to **`'cust_id'`** using the `rename` method along with a dictionary.\n",
    ">\n",
    "> *(e)* Utilize the `merge` method to execute a **left join** between the `DataFrames` **`transactions`** and **`customer`** based on the `'cust_id'` column. Name the resulting `DataFrame` **`fusion`**.\n",
    ">\n",
    "> *(f)* Did the merging process result in any NAs?\n",
    ">\n",
    "> *(g)* Display the initial rows of **`fusion`**. What are the newly introduced columns?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cust_id             0\n",
      "tran_date           0\n",
      "prod_subcat_code    0\n",
      "prod_cat_code       0\n",
      "qty                 0\n",
      "rate                0\n",
      "tax                 0\n",
      "total_amt           0\n",
      "store_type          0\n",
      "DOB                 0\n",
      "Gender              0\n",
      "city_code           0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>tran_date</th>\n",
       "      <th>prod_subcat_code</th>\n",
       "      <th>prod_cat_code</th>\n",
       "      <th>qty</th>\n",
       "      <th>rate</th>\n",
       "      <th>tax</th>\n",
       "      <th>total_amt</th>\n",
       "      <th>store_type</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Gender</th>\n",
       "      <th>city_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>270351</td>\n",
       "      <td>28-02-2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>-772.0</td>\n",
       "      <td>405.300</td>\n",
       "      <td>-4265.300</td>\n",
       "      <td>e-Shop</td>\n",
       "      <td>26-09-1981</td>\n",
       "      <td>M</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>270384</td>\n",
       "      <td>27-02-2014</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1497.0</td>\n",
       "      <td>785.925</td>\n",
       "      <td>-8270.925</td>\n",
       "      <td>e-Shop</td>\n",
       "      <td>11-05-1973</td>\n",
       "      <td>F</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>273420</td>\n",
       "      <td>24-02-2014</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-791.0</td>\n",
       "      <td>166.110</td>\n",
       "      <td>-1748.110</td>\n",
       "      <td>TeleShop</td>\n",
       "      <td>27-07-1992</td>\n",
       "      <td>M</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>271509</td>\n",
       "      <td>24-02-2014</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1363.0</td>\n",
       "      <td>429.345</td>\n",
       "      <td>-4518.345</td>\n",
       "      <td>e-Shop</td>\n",
       "      <td>08-06-1981</td>\n",
       "      <td>M</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>273420</td>\n",
       "      <td>23-02-2014</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-791.0</td>\n",
       "      <td>166.110</td>\n",
       "      <td>-1748.110</td>\n",
       "      <td>TeleShop</td>\n",
       "      <td>27-07-1992</td>\n",
       "      <td>M</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cust_id   tran_date  prod_subcat_code  prod_cat_code  qty    rate      tax  \\\n",
       "0   270351  28-02-2014                 1              1   -5  -772.0  405.300   \n",
       "1   270384  27-02-2014                 5              3   -5 -1497.0  785.925   \n",
       "2   273420  24-02-2014                 6              5   -2  -791.0  166.110   \n",
       "3   271509  24-02-2014                11              6   -3 -1363.0  429.345   \n",
       "4   273420  23-02-2014                 6              5   -2  -791.0  166.110   \n",
       "\n",
       "   total_amt store_type         DOB Gender  city_code  \n",
       "0  -4265.300     e-Shop  26-09-1981      M        5.0  \n",
       "1  -8270.925     e-Shop  11-05-1973      F        8.0  \n",
       "2  -1748.110   TeleShop  27-07-1992      M        8.0  \n",
       "3  -4518.345     e-Shop  08-06-1981      M        3.0  \n",
       "4  -1748.110   TeleShop  27-07-1992      M        8.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We rename the 'customer_Id' column to 'cust_id' for merging\n",
    "customer = customer.rename(columns = {'customer_Id': 'cust_id'})\n",
    "\n",
    "# Left join between transactions and customer on the 'cust_id' column\n",
    "fusion = transactions.merge(right = customer, on = 'cust_id', how = 'left')\n",
    "\n",
    "# The merging did not produce NAs\n",
    "print(fusion.isna().sum())\n",
    "\n",
    "# The columns DOB, Gender, city_code have been added to transactions\n",
    "fusion.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> The merging went well and produced no NaNs. However, the index of the `DataFrame` is no longer the column **`transaction_id'`** and has been reset with the default index (`0`,` 1`, `2` , ...).\n",
    ">\n",
    "> You can re-define the index of a `DataFrame` using the **`set_index`** method.\n",
    ">\n",
    "> This method can take as argument:\n",
    ">> * The **name** of a column to use as indexing.\n",
    ">> * A `numpy` `array` or `pandas` `Series`  with the same number of rows as the `DataFrame` calling the method.\n",
    ">\n",
    "> <span style=\"color:#09b038; text-decoration : underline\"> Example: </span><br>\n",
    ">\n",
    "> Let `df` be the following `DataFrame`:\n",
    ">\n",
    "> |       | Name     | Car       |\n",
    "> |-------|----------|-----------|\n",
    "> | **0** | Lila     | Twingo    |\n",
    "> | **1** | Tiago    | Clio      |\n",
    "> | **2** | Berenice | C4 Cactus |\n",
    "> | **3** | Joseph   | Twingo    |\n",
    "> | **4** | Kader    | Swift     |\n",
    "> | **5** | Romy     | Scenic    |\n",
    ">\n",
    "> We can set the column `'Name'` as the new index:\n",
    ">\n",
    "> ```python\n",
    "> df = df.set_index('Name')\n",
    "> ```\n",
    ">\n",
    "> This will produce the following `DataFrame`:\n",
    ">\n",
    "> | <br><br><br> **Name** | Car       |\n",
    "> |:----------------------|:----------|\n",
    "> | **Lila**              | Twingo    |\n",
    "> | **Tiago**             | Clio      |\n",
    "> | **Berenice**          | C4 Cactus |\n",
    "> | **Joseph**            | Twingo    |\n",
    "> | **Kader**             | Swift     |\n",
    "> | **Romy**              | Scenic    |\n",
    ">\n",
    "> We can also define the index from an `array`, from a `Series`, etc:\n",
    ">\n",
    "> ```python\n",
    "> # New index to use\n",
    "> new_index = ['10000' + str(i) for i in range(6)]\n",
    "> print(new_index)\n",
    "> >>> ['100000', '100001', '100002', '100003', '100004', '100005']\n",
    ">\n",
    "> # Using an array or a Series is equivalent\n",
    "> index_array = np.array(new_index)\n",
    "> index_series = pd.Series(new_index)\n",
    ">\n",
    ">\n",
    "> df = df.set_index(index_array)\n",
    "> df = df.set_index(index_series)\n",
    "> ```\n",
    ">\n",
    "> This will produce the following `DataFrame`:\n",
    ">\n",
    "> |            | Name     | Car       |\n",
    "> |-----------:|:---------|:----------|\n",
    "> | **100000** | Lila     | Twingo    |\n",
    "> | **100001** | Tiago    | Clio      |\n",
    "> | **100002** | Berenice | C4 Cactus |\n",
    "> | **100003** | Joseph   | Twingo    |\n",
    "> | **100004** | Kader    | Swift     |\n",
    "> | **100005** | Romy     | Scenic    |\n",
    "\n",
    "> To return to the default numeric indexing, we use the **`reset_index`** method of the `DataFrame`:\n",
    ">\n",
    "> ```python\n",
    "> df = df.reset_index()\n",
    "> ```\n",
    ">\n",
    "> The indexing column that was used **is not deleted**. A new column will be created containing the old index:\n",
    ">\n",
    "> |       | index  | Name | Car |\n",
    "> |------:|-------:|:---------|:----------|\n",
    "> | **0** | 100000 | Lila | Twingo |\n",
    "> | **1** | 100001 | Tiago | Clio |\n",
    "> | **2** | 100002 | Berenice | C4 Cactus |\n",
    "> | **3** | 100003 | Joseph | Twingo |\n",
    "> | **4** | 100004 | Kader | Swift |\n",
    "> | **5** | 100005 | Romy | Scenic |\n",
    ">\n",
    "\n",
    "Merging `transactions` and` customer` removed the index of `transactions`.\n",
    "\n",
    "The index of a `DataFrame` can be retrieved using its `.index` attribute.\n",
    "\n",
    "* **(h)** Take the index from `transactions` and use it to index `fusion`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>tran_date</th>\n",
       "      <th>prod_subcat_code</th>\n",
       "      <th>prod_cat_code</th>\n",
       "      <th>qty</th>\n",
       "      <th>rate</th>\n",
       "      <th>tax</th>\n",
       "      <th>total_amt</th>\n",
       "      <th>store_type</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Gender</th>\n",
       "      <th>city_code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80712190438</th>\n",
       "      <td>270351</td>\n",
       "      <td>28-02-2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>-772.0</td>\n",
       "      <td>405.300</td>\n",
       "      <td>-4265.300</td>\n",
       "      <td>e-Shop</td>\n",
       "      <td>26-09-1981</td>\n",
       "      <td>M</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29258453508</th>\n",
       "      <td>270384</td>\n",
       "      <td>27-02-2014</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1497.0</td>\n",
       "      <td>785.925</td>\n",
       "      <td>-8270.925</td>\n",
       "      <td>e-Shop</td>\n",
       "      <td>11-05-1973</td>\n",
       "      <td>F</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51750724947</th>\n",
       "      <td>273420</td>\n",
       "      <td>24-02-2014</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-791.0</td>\n",
       "      <td>166.110</td>\n",
       "      <td>-1748.110</td>\n",
       "      <td>TeleShop</td>\n",
       "      <td>27-07-1992</td>\n",
       "      <td>M</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93274880719</th>\n",
       "      <td>271509</td>\n",
       "      <td>24-02-2014</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1363.0</td>\n",
       "      <td>429.345</td>\n",
       "      <td>-4518.345</td>\n",
       "      <td>e-Shop</td>\n",
       "      <td>08-06-1981</td>\n",
       "      <td>M</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51750724947</th>\n",
       "      <td>273420</td>\n",
       "      <td>23-02-2014</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-791.0</td>\n",
       "      <td>166.110</td>\n",
       "      <td>-1748.110</td>\n",
       "      <td>TeleShop</td>\n",
       "      <td>27-07-1992</td>\n",
       "      <td>M</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cust_id   tran_date  prod_subcat_code  prod_cat_code  qty  \\\n",
       "transaction_id                                                              \n",
       "80712190438      270351  28-02-2014                 1              1   -5   \n",
       "29258453508      270384  27-02-2014                 5              3   -5   \n",
       "51750724947      273420  24-02-2014                 6              5   -2   \n",
       "93274880719      271509  24-02-2014                11              6   -3   \n",
       "51750724947      273420  23-02-2014                 6              5   -2   \n",
       "\n",
       "                  rate      tax  total_amt store_type         DOB Gender  \\\n",
       "transaction_id                                                             \n",
       "80712190438     -772.0  405.300  -4265.300     e-Shop  26-09-1981      M   \n",
       "29258453508    -1497.0  785.925  -8270.925     e-Shop  11-05-1973      F   \n",
       "51750724947     -791.0  166.110  -1748.110   TeleShop  27-07-1992      M   \n",
       "93274880719    -1363.0  429.345  -4518.345     e-Shop  08-06-1981      M   \n",
       "51750724947     -791.0  166.110  -1748.110   TeleShop  27-07-1992      M   \n",
       "\n",
       "                city_code  \n",
       "transaction_id             \n",
       "80712190438           5.0  \n",
       "29258453508           8.0  \n",
       "51750724947           8.0  \n",
       "93274880719           3.0  \n",
       "51750724947           8.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We retrieve the index of transactions\n",
    "new_index = transactions.index\n",
    "\n",
    "# We set the new index of fusion\n",
    "fusion = fusion.set_index(new_index)\n",
    "fusion.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Sort and order the values of a `DataFrame`: `sort_values` and `sort_index` methods.\n",
    "\n",
    "\n",
    "> The `sort_values` method allows you to sort the rows of a `DataFrame` according to the values of one or more columns.\n",
    ">\n",
    "> The header of this method is as follows:\n",
    ">\n",
    "> `sort_values(by, ascending, ...)`\n",
    ">\n",
    ">> - The `by` parameter allows you to specify on which column(s) the sort is performed.\n",
    ">>\n",
    ">> - The `ascending` parameter is a boolean value (`True` or `False`) determining whether the sorting order is ascending or descending. By default this parameter is set to `True`.\n",
    ">\n",
    "> <span style=\"color:#09b038; text-decoration : underline\"> Example: </span><br>\n",
    ">\n",
    "> Consider the `DataFrame` `df` describing students:\n",
    ">\n",
    ">\n",
    "> | Name     | Grade | Bonus points |\n",
    "> |----------|-------|--------------|\n",
    "> | 'Amelie' | A     | 1            |\n",
    "> | 'Marin'  | F     | 1            |\n",
    "> | 'Pierre' | A     | 2            |\n",
    "> | 'Zoe'    | C     | 1            |\n",
    ">\n",
    "> First of all, we will sort the rows on a single column, for example the column `'Bonus Points'`:\n",
    ">\n",
    "> ```python\n",
    "> # We sort the DataFrame df on the column 'Bonus Points'\n",
    "> df_sorted = df.sort_values(by ='Bonus Points', ascending = True)\n",
    "> ```\n",
    ">\n",
    "> We obtain the following result:\n",
    ">\n",
    "> <br/>\n",
    "> <img src='https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/pd_sort_values_en.png' style=\"height:400px\">\n",
    "> <br>\n",
    ">\n",
    "> The rows of the `DataFrame` `df_sorted` are therefore sorted in **ascending order** of the **`'Bonus points'`** column. However, if we look at the column `'Grade'`, we see that it is not sorted alphabetically for the common values of `'Bonus Points'`.\n",
    ">\n",
    "> This can be remedied by also sorting by the `'Grade'` column:\n",
    ">\n",
    ">\n",
    "> ```python\n",
    "> # We first sort the DataFrame df by the column 'Bonus Points' then in case of equality, by the column 'Grade'.\n",
    "> df_sorted = df.sort_values(by = ['Bonus Points', 'Grade'], ascending = True)\n",
    "> ```\n",
    ">\n",
    "> <br/>\n",
    "> We obtain the following result:\n",
    ">\n",
    "> <br><br>\n",
    ">\n",
    "> <img src='https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/pd_sort_values_2_en.png' style=\"height:600px\">\n",
    ">\n",
    "> <br>\n",
    ">\n",
    "> <br/>\n",
    ">\n",
    "> The **`sort_index`** method is used to sort a `DataFrame` based on its index.\n",
    ">\n",
    "> When the index is the default numerical one, this method may not offer significant advantages. However, it can frequently be utilized in conjunction with the `set_index` method of a `DataFrame`, as we've recently covered.\n",
    ">\n",
    ">\n",
    "> <span style=\"color:#09b038; text-decoration : underline\"> Example: </span><br>\n",
    ">\n",
    "> ```py\n",
    "> # We define the column 'Grade' as the index of df\n",
    "> df = df.set_index('Grade')\n",
    ">\n",
    "> # We sort the DataFrame df according to its index\n",
    "> df = df.sort_index()\n",
    ">\n",
    "> ```\n",
    ">\n",
    "> This produces the following `DataFrame`:\n",
    ">\n",
    "> | <br><br><br> **Grade**| Name    | Bonus points |\n",
    "> |-----------------------|---------|--------------|\n",
    "> | **A**                 |'Amelie' | 1            |\n",
    "> | **A**                 |'Peter'  | 2            |\n",
    "> | **C**                 |'Zoe'    | 1            |\n",
    "> | **F**                 |'Sailor' | 1            |\n",
    ">             \n",
    ">\n",
    ">Consider the two following `DataFrames` containing boat rental data.\n",
    ">\n",
    ">Below are the `boats` `DataFrame`:\n",
    ">\n",
    ">\n",
    ">|       | boat_name | color  | reservation_number | n_reservations |\n",
    ">|------:|:----------|:-------|-------------------:|---------------:|\n",
    ">| **0** | Julia     | blue   | 2                  | 34             |\n",
    ">| **1** | Siren     | green  | 3                  | 10             |\n",
    ">| **2** | Sea Sons  | red    | 6                  | 20             |\n",
    ">| **3** | Hercules  | blue   | 1                  | 41             |\n",
    ">| **4** | Cesar     | yellow | 4                  | 12             |\n",
    ">| **5** | Minerva   | green  | 5                  | 16             |\n",
    ">\n",
    ">\n",
    ">And the `clients` `DataFrame`:\n",
    ">\n",
    ">|       | client_id | client_name | reservation_id |\n",
    ">|------:|----------:|:------------|---------------:|\n",
    ">| **0** | 91        | Marie       | 1              |\n",
    ">| **1** | 154       | Anna        | 2              |\n",
    ">| **2** | 124       | Yann        | 3              |\n",
    ">| **3** | 320       | Lea         | 7              |\n",
    ">| **4** | 87        | Marc        | 9              |\n",
    ">| **5** | 22        | Yassine     | 10             |\n",
    "\n",
    "* **(a)** Run the following cell to instantiate these `DataFrames`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the data dictionnaries\n",
    "data_boats = {'boat_name'         : ['Julia', 'Siren', 'Sea Sons', 'Hercules', 'Cesar', 'Minerva'], \n",
    "              'color'             : ['blue', 'green', 'red', 'blue', 'yellow', 'green'],\n",
    "              'reservation_number': [2, 3, 6, 1, 4, 5],\n",
    "              'n_reservations'    : [34, 10, 20, 41, 12, 16]}\n",
    "\n",
    "data_clients = {'client_id'     : [91, 154, 124, 320, 87, 22], \n",
    "                'client_name'   : ['Marie', 'Anna', 'Yann', 'Lea', 'Marc', 'Yassine'],\n",
    "                'reservation_id': [1, 2, 3, 7, 9, 10]}\n",
    "\n",
    "# Instantiation of the DataFrames\n",
    "boats = pd.DataFrame(data_boats)\n",
    "clients = pd.DataFrame(data_clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> We want to easily determine which customer has reserved the boats of the `boats` `DataFrame`. To do this, we can simply merge the `DataFrames`.\n",
    "\n",
    "* **(b)** Rename the `'reservation_number'` column from `boats` to `'reservation_id'` using the `rename` method.\n",
    "\n",
    "\n",
    "* **(c)** In a `DataFrame` named **`boats_clients`**, perform the **left join** between `boats` (left) and `clients` (right).\n",
    "\n",
    "\n",
    "* **(d)** Set the column `'boat_name'` as index of the `boats_clients` `DataFrame`.\n",
    "\n",
    "\n",
    "* **(e)** Using the `loc` method, find who reserved the boats `'Julia'` and `'Siren'`.\n",
    "\n",
    "\n",
    "* **(f)** Using the `isna` method applied to the `client_name` column, determine the boats that have not been reserved.\n",
    "\n",
    "\n",
    "* **(g)** The number of times a boat has been reserved so far is indicated by the column `'n_reservations'`. Using the **`sort_values`** method, determine the name of the customer who reserved the **blue** boat with the most reservations to date.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The client who reserved 'Julia' is: Anna\n",
      "The client who reserved 'Siren' is: Yann\n",
      "\n",
      "\n",
      "The boats which have not been reserved are: ['Sea Sons', 'Cesar', 'Minerva']\n",
      "The customer who has booked the blue boat with the most reservations is : Marie\n"
     ]
    }
   ],
   "source": [
    "# We rename the column 'number_reservation'\n",
    "boats = boats.rename(columns = {'reservation_number': 'reservation_id'})\n",
    "\n",
    "# We perform the left join between boats and clients\n",
    "boats_clients = boats.merge(clients, on = 'reservation_id', how = 'left')\n",
    "\n",
    "# We set the column 'boat_name' as the index of boats_clients\n",
    "boats_clients = boats_clients.set_index(\"boat_name\")\n",
    "\n",
    "# Who reserved 'Julia' and 'Siren'?\n",
    "print(\"The client who reserved 'Julia' is:\", boats_clients.loc['Julia', 'client_name'])\n",
    "print(\"The client who reserved 'Siren' is:\", boats_clients.loc['Siren', 'client_name'])\n",
    "print(\"\\n\")\n",
    "\n",
    "# Which boats have not been reserved?\n",
    "boats_not_reserved = boats_clients[boats_clients['client_name'].isna()]\n",
    "print(\"The boats which have not been reserved are:\", [boat for boat in boats_not_reserved.index])\n",
    "\n",
    "# Which client reserved the BLUE boat with the MOST reservations to date?\n",
    "most_reserved_blue_boat = boats_clients[boats_clients['color']=='blue'].sort_values(by = 'n_reservations', ascending = False).iloc[0]\n",
    "print(\"The customer who has booked the blue boat with the most reservations is :\", most_reserved_blue_boat['client_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 4. Grouping the elements of a `DataFrame`: `groupby`, `agg` and `crosstab` methods.\n",
    "\n",
    "> The **`groupby`** method allows you to **group the rows** of a `DataFrame` which share a **common** value on a given column.\n",
    ">\n",
    "> **This method does not return a `DataFrame`.** The object returned by the `groupby` method is an object of the **`DataFrameGroupBy`** class.\n",
    ">\n",
    ">\n",
    "> This class is used to perform operations such as calculating statistics (sum, average, maximum, etc.) for each category of the column on which the rows are grouped.\n",
    ">\n",
    "> The general structure of a **`groupby` operation** is as follows:\n",
    ">\n",
    ">> * **Split** the data.\n",
    ">> * **Apply** a function.\n",
    ">> * **Combine** the results.\n",
    ">\n",
    ">\n",
    "> <span style=\"color:#09b038; text-decoration : underline\"> Example: </span><br>\n",
    ">\n",
    "> Assuming all the boats in the `boats` `DataFrame` are identical in terms of age, we aim to determine if the color of a boat impacts its reservation frequency. To do this, we will calculate the average number of reservations per boat for each color.\n",
    ">\n",
    "> The process involves:\n",
    ">\n",
    ">> * **Splitting** the boats based on color.\n",
    ">> * **Applying** the **`mean`** function to determine the average number of reservations.\n",
    ">> * **Combining** the outcomes in a `DataFrame` for easy comparison.\n",
    ">\n",
    "> To achieve this, we can utilize the **`groupby`** method followed by the **`mean`** method, resulting in:\n",
    ">\n",
    "> <br>\n",
    ">\n",
    "> <img src= 'https://assets-datascientest.s3-eu-west-1.amazonaws.com/train/pd_groupby_en.png' style=\"height:350px\">\n",
    ">\n",
    "> <br>\n",
    ">\n",
    "> All the usual statistical methods (`count`,` mean`, `max`, etc.) can be used as a suffix of the `groupby` method. These will only be applied on columns of compatible type.\n",
    ">\n",
    "> For each column, you can specify which function should be used in the **Apply** step of a `groupby` operation. To do this, we use the **`agg`** method of the `DataFrameGroupBy` class. This involves providing a **dictionary** where each **key** represents the **name** of a column, and the corresponding **value** indicates the **function** to be applied.\n",
    ">\n",
    ">\n",
    "> <span style=\"color:#09b038; text-decoration : underline\"> Example: </span><br>\n",
    ">\n",
    "> Let us go back to the `transactions` `DataFrame`:\n",
    ">\n",
    "> | transaction_id | cust_id | tran_date  | prod_subcat_code | prod_cat_code | qty | rate | tax     | total_amt | store_type |\n",
    "> |---------------:|--------:|:-----------|-----------------:|--------------:|----:|-----:|--------:|----------:|:-----------|\n",
    "> | 80712190438    | 270351  | 28-02-2014 | 1                | 1             | -5  |-772  | 405.3   | -4265.3   | e-Shop     |\n",
    "> | 29258453508    | 270384  | 27-02-2014 | 5                | 3             | -5  |-1497 | 785.925 | -8270.92  | e-Shop     |\n",
    "> | 51750724947    | 273420  | 24-02-2014 | 6                | 5             | -2  |-791  | 166.11  | -1748.11  | TeleShop   |\n",
    "> | 93274880719    | 271509  | 24-02-2014 | 11               | 6             | -3  |-1363 | 429.345 | -4518.35  | e-Shop     |\n",
    "> | 51750724947    | 273420  | 23-02-2014 | 6                | 5             | -2  |-791  | 166.11  | -1748.11  | TeleShop   |\n",
    ">\n",
    ">\n",
    "> We want to determine, **for each customer** (`cust_id`), the **minimum**, **maximum** and the **total amount** spent from the `total_amt` column. We also want to know **how many types of stores** the customer has made a transaction in (`store_type` column).\n",
    ">\n",
    "> We can perform these calculations using a **`groupby`** operation:\n",
    ">\n",
    ">> * **Split** the transactions by the **customer identifier**.\n",
    ">> * For the **`total_amt`** column, calculate the minimum (`min`), maximum (`max`) and the sum (`sum`). For the **`store_type`** column, count the **number of unique categories taken**.\n",
    ">> * **Combine** the results in a `DataFrame`.\n",
    ">\n",
    "> To find the number of unique categories taken by the `store_type` column, we will use the following **`lambda`** function:\n",
    ">\n",
    "> ```python\n",
    "> import numpy as np\n",
    ">\n",
    "> n_categories = lambda store_type: len(np.unique(store_type))\n",
    "> ```\n",
    ">\n",
    ">> * The `lambda` function must take as argument a **column** and return a **number**.\n",
    ">> * The **`np.unique`** function determines the unique **categories** that appear in a sequence.\n",
    ">> * The **`len`** function counts the number of elements in a sequence, i.e. its length.\n",
    ">\n",
    "> Thus, this function will allow us to determine the number of unique categories for the `store_type` column.\n",
    ">\n",
    "> To apply these functions in the `groupby` operation, we'll use a dictionary whose **keys** are the **columns** to process and the **values** the **functions** to use.\n",
    ">\n",
    "> ```python\n",
    "> functions_to_apply = {\n",
    "> # Classic statistical methods can be entered with\n",
    "> # strings\n",
    "> 'total_amt': ['min', 'max', 'sum'],\n",
    "> 'store_type': n_categories\n",
    ">}\n",
    "> ```\n",
    ">\n",
    "> This dictionary can now be fed into the **`agg`** method to perform the `groupby` operation:\n",
    ">\n",
    "> ```python\n",
    "> transactions.groupby('cust_id').agg(functions_to_apply)\n",
    "> ```\n",
    ">\n",
    "> Which produces the following `DataFrame`:\n",
    ">\n",
    "> | <br><br><br><br><br> cust_id | total_amt <br><br> min | <br><br> max | <br><br> sum | store_type <br><br> <lambda\\> |\n",
    "> |-----------------------------:|:-----------------------|:-------------|:-------------|--------------------------------:|\n",
    "> | **266783**                   | -5838.82               | 5838.82      | 3113.89      | 2                               |\n",
    "> | **266784**                   |  442                   | 4279.66      | 5694.07      | 3                               |\n",
    "> | **266785**                   | -6828.9                | 6911.77      | 21613.8      | 3                               |\n",
    "> | **266788**                   |  1312.74               | 1927.12      | 6092.97      | 3                               |\n",
    "> | **266794**                   | -135,915               | 4610.06      | 27981.9      | 4                               |\n",
    "\n",
    "* **(a)** Perform a `groupby` operation to calculate, for each customer, the following statistics based on the quantity of items purchased in a transaction (**`qty`** column):\n",
    "> - The maximum quantity.\n",
    "> - The minimum quantity.\n",
    "> - The median quantity.\n",
    ">\n",
    ">To achieve this, you should filter the transactions where the quantity is negative using conditional indexing (`qty[qty > 0]`) within a `lambda` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  boat_name color  reservation_id  n_reservations\n",
      "0     Julia  blue               2              34\n",
      "3  Hercules  blue               1              41\n",
      "------------\n",
      "  boat_name  color  reservation_id  n_reservations\n",
      "1     Siren  green               3              10\n",
      "5   Minerva  green               5              16\n",
      "------------\n",
      "  boat_name color  reservation_id  n_reservations\n",
      "2  Sea Sons   red               6              20\n",
      "------------\n",
      "  boat_name   color  reservation_id  n_reservations\n",
      "4     Cesar  yellow               4              12\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "color\n",
       "blue      37.5\n",
       "green     13.0\n",
       "red       20.0\n",
       "yellow    12.0\n",
       "Name: n_reservations, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Achtung: BSP von oben geht so nicht, wenn wir uns die verschiedenen Gruppen angucken können wir sehen dass neben der Spalte \"color\" (die wird beim gruppieren \n",
    "# als Zeilenindex verwendet) auch noch die Spalte boat_name in jeder Gruppe haben. Mit dieser Spalte kann kein mean verwendet werden und der Aufruf führt zu einem Fehler:\n",
    "# boats.groupby(\"color\").mean() -> Fehler wegen Spalte boat_color\n",
    "# boats.groupby(\"color\")[\"n_reservations\"].mean() -> Mittelwert der Reservierungen für jede Farbe\n",
    "for g in boats.groupby(\"color\"): \n",
    "    print(g[1],end=\"\\n------------\\n\")\n",
    "boats.groupby(\"color\")[\"n_reservations\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_reservations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blue</th>\n",
       "      <td>37.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>green</th>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>red</th>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yellow</th>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_reservations\n",
       "color                 \n",
       "blue              37.5\n",
       "green             13.0\n",
       "red               20.0\n",
       "yellow            12.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALternative:\n",
    "boats_res = boats[[\"color\", \"n_reservations\"]] # wenn unser DataFrame nur die beiden Spalten enthält, dann funktioniert es\n",
    "boats_res.groupby(\"color\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">qty</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cust_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>266783</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266784</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266785</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266788</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266794</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        qty           \n",
       "        max min median\n",
       "cust_id               \n",
       "266783    4   1    2.5\n",
       "266784    5   2    3.0\n",
       "266785    5   2    5.0\n",
       "266788    4   1    1.5\n",
       "266794    4   1    3.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_max = lambda qty: qty[qty > 0].max()\n",
    "my_min = lambda qty: qty[qty > 0].min()\n",
    "my_median = lambda qty: qty[qty > 0].median()\n",
    "f_to_apply = {'qty':[my_max,my_min,my_median]}\n",
    "client_stats = transactions.groupby('cust_id').agg(f_to_apply)\n",
    "client_stats = client_stats.rename({client_stats.columns[0][1]:'max',\n",
    "                                    client_stats.columns[1][1]:'min',\n",
    "                                    client_stats.columns[2][1]:'median'}, \n",
    "                                    axis=1)\n",
    "client_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> Another way of grouping and summarizing data is to use the `crosstab` function of `pandas` which, as its name suggests, is used to crosstab the data in the columns of a `DataFrame`.\n",
    ">\n",
    "> A crosstab allows us to visualize the **appearance frequency** of **pairs of categories** in a `DataFrame`.\n",
    ">\n",
    "> <span style=\"color:#09b038; text-decoration : underline\"> Example :</span><br> \n",
    ">\n",
    "> In the `transactions` `DataFrame`, we want to know which are the most frequent category and subcategory pairs (`prod_cat_code` and `prod_subcat_code` columns)\n",
    ">\n",
    "> The `crosstab` function of pandas gives us this result:\n",
    "> \n",
    "> ```python\n",
    "> column1 = transactions['prod_cat_code']\n",
    "> column2 = transactions['prod_subcat_code']\n",
    "> pd.crosstab(column1, column2)\n",
    "> ```\n",
    "> \n",
    "> This instruction produces the following `DataFrame`:\n",
    ">\n",
    "> |prod_subcat_code <br><br> prod_cat_code|-1 | 1  | 2  | 3  | 4  | 5 | 6 | 7  | 8 | 9 | 10 | 11 | 12 |\n",
    "> |--------------------------------------:|--:|---:|---:|---:|---:|--:|--:|---:|--:|--:|---:|---:|---:|\n",
    "> | **1**                                 |4  |1001|0   |981 |958 |0  |0  |0   |0  |0  |0   |0   |0   |\n",
    "> | **2**                                 |4  |934 |0   |1040|1005|0  |0  |0   |0  |0  |0   |0   |0   |\n",
    "> | **3**                                 |11 |0   |0   |0   |1020|950|0  |0   |966|976|945 |0   |0   |\n",
    "> | **4**                                 |5  |993 |0   |0   |988 |0  |0  |0   |0  |0  |0   |0   |0   |\n",
    "> | **5**                                 |3  |0   |0   |1023|0   |0  |984|1037|0  |0  |998 |1029|962 |\n",
    "> | **6**                                 |5  |0   |1002|0   |0   |0  |0  |0   |0  |0  |1025|1013|1057|\n",
    "> \n",
    "> The `(i, j)` cell of the resulting `DataFrame` contains the number of rows of the `DataFrame` having the category `i` for column 1 and the category `j` for column 2.\n",
    ">\n",
    "> Thus, it is easy to determine, for example, that **the dominant subcategories** of the category **`4`** are `1` and `4`.\n",
    "> \n",
    "> \n",
    "> The **`normalize`** argument of `crosstab` allows to display frequencies as a percentage.\n",
    ">\n",
    "> Thus, the argument **`normalize = 1`** normalizes the table over the axis 1 of the crosstab, i.e. its **columns**:\n",
    ">\n",
    "> ```python\n",
    "> #We recover the year of the transaction.\n",
    "> column1 = transactions['tran_date'].apply(lambda x: x.split('-')[2]).astype(int)\n",
    "> \n",
    "> column2 = transactions['store_type']\n",
    "> \n",
    "> pd.crosstab(column1,\n",
    ">             column2,\n",
    ">             normalize = 1)\n",
    "> ```\n",
    ">\n",
    "> This produces the following `DataFrame`:\n",
    "> \n",
    "> | <br><br> store_type <br><br> tran_date | Flagship store | MBR       | TeleShop  | e-Shop    |\n",
    "> |---------------------------------------:|---------------:|----------:|----------:|----------:|\n",
    "> | **2011**                               | 0.291942       | 0.323173  | 0.283699  | 0.306947  |\n",
    "> | **2012**                               | 0.331792       | 0.322093  | 0.336767  | 0.322886  |\n",
    "> | **2013**                               | 0.335975       | 0.3115    | 0.332512  | 0.320194  |\n",
    "> | **2014**                               | 0.0402906      | 0.0432339 | 0.0470219 | 0.0499731 |\n",
    ">\n",
    "> This `DataFrame` allows us to say that **33.5975%** of the transactions made in a **`'Flagship store'`** took place in **2013**.\n",
    ">\n",
    "> Conversely, by entering the argument **`normalize = 0`**, the crosstab is normalized over each **row**:\n",
    "> \n",
    "> | <br><br> store_type <br><br> tran_date | Flagship store | MBR      | TeleShop | e-Shop   |\n",
    "> |---------------------------------------:|---------------:|---------:|---------:|---------:|\n",
    "> |**2011**                                | 0.191121       | 0.21548  | 0.182617 | 0.410781 |\n",
    "> |**2012**                                | 0.20096        | 0.198693 | 0.20056  | 0.399787 |\n",
    "> |**2013**                                | 0.205522       | 0.194074 | 0.2      | 0.400404 |\n",
    "> |**2014**                                | 0.173132       | 0.189215 | 0.198675 | 0.438978 |\n",
    ">\n",
    "> By normalizing over the rows, we find out that the transactions made in an **`'e-Shop'`** account for **41.0781%** of the transactions of the year **2011**.\n",
    ">\n",
    ">\n",
    ">In the `covid_tests.csv` file, we have a dataset of 200 COVID-19 tests. The columns of this dataset are as follows:\n",
    ">\n",
    ">>* `'patient_id'`: ID of the patient tested.\n",
    ">>* `'test_result'`: Result of the test. Equals 1 if the patient is tested positive and 0 otherwise.\n",
    ">>* `'infected'`: Equals `1` if the patient was actually infected and `0` otherwise.\n",
    "\n",
    "\n",
    "* **(b)** Load the dataset contained in the `covid_tests.csv` file. The values are separated by the character `';'`.\n",
    "\n",
    "\n",
    "* **(c)** Use the `pd.crosstab` function to determine the number of **False Negatives** produced by this test. (A false negative occurs when the test determines that the patient is not infected when they actually are.)\n",
    "\n",
    "\n",
    "* **(d)** What is the false positive rate of the test? The false positive rate is the **proportion** of false positives in relation to the number of people that are not infected. (A false positive occurs when the test determines that the patient is infected when they are not.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>infected</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_result</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.040541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.959459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "infected            0         1\n",
       "test_result                    \n",
       "0            0.944444  0.040541\n",
       "1            0.055556  0.959459"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset in 'covid_tests.csv'\n",
    "covid_df = pd.read_csv(\"C:/Users/OlhaIshchenko/Documents/Daten_Analyse/unterricht/csv_Datei/covid_tests.csv\", \n",
    "                       sep = ';', index_col = 'patient_id')\n",
    "covid_df.head()\n",
    "\n",
    "\n",
    "# Crosstab of the test results with reality\n",
    "pd.crosstab(covid_df['test_result'], \n",
    "            covid_df['infected'])\n",
    "\n",
    "# There are 3 false negatives\n",
    "\n",
    "\n",
    "pd.crosstab(covid_df['test_result'], \n",
    "            covid_df['infected'],\n",
    "            normalize = 1)\n",
    "\n",
    "# The false positive rate is about 5,6%\n",
    "# 94,4% of healthy people are true negatives"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".my_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
